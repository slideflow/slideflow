


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>slideflow.norm &mdash; slideflow 3.0.0 documentation</title>















  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex/" />
    <link rel="search" title="Search" href="../../../search/" />




  <script src="../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/IBMPlexSans/IBMPlexSans-Light.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexSans/IBMPlexSans-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexSans/IBMPlexSans-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexSans/IBMPlexSans-MediumItalic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
  <script defer data-domain="slideflow.dev" src="https://plausible.io/js/script.js"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://slideflow.dev" aria-label="Slideflow"></a>

      <div class="main-menu">
        <ul>
          <li class="active">
            <a href="https://slideflow.dev">Docs</a>
          </li>

          <li>
            <a href="https://slideflow.dev/tutorial1/">Tutorials</a>
          </li>

          <li>
            <a href="https://github.com/slideflow/slideflow">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">





    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">





                <div class="version">
                  3.0
                </div>









<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search/" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>


          </div>







              <p class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../installation/">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../overview/">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../quickstart/">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../project_setup/">Setting up a Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../datasets_and_val/">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../slide_processing/">Slide Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../training/">Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../evaluation/">Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../posthoc/">Layer Activations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../uq/">Uncertainty Quantification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../features/">Generating Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mil/">Multiple-Instance Learning (MIL)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ssl/">Self-Supervised Learning (SSL)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../stylegan/">Generative Networks (GANs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../saliency/">Saliency Maps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../segmentation/">Tissue Segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cellseg/">Cell Segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../custom_loops/">Custom Training Loops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../studio/">Slideflow Studio: Live Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../troubleshooting/">Troubleshooting</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tfrecords/">TFRecords: Reading and Writing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dataloaders/">Dataloaders: Sampling and Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../custom_extractors/">Custom Feature Extractors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tile_labels/">Strong Supervision with Tile Labels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../plugins/">Creating a Slideflow Plugin</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../slideflow/">slideflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../project/">slideflow.Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dataset/">slideflow.Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dataset_features/">slideflow.DatasetFeatures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../heatmap/">slideflow.Heatmap</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../model_params/">slideflow.ModelParams</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mosaic/">slideflow.Mosaic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../slidemap/">slideflow.SlideMap</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../biscuit/">slideflow.biscuit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../slideflow_cellseg/">slideflow.cellseg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../io/">slideflow.io</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../io_tensorflow/">slideflow.io.tensorflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../io_torch/">slideflow.io.torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../gan/">slideflow.gan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../grad/">slideflow.grad</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mil_module/">slideflow.mil</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../model/">slideflow.model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../model_tensorflow/">slideflow.model.tensorflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../model_torch/">slideflow.model.torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../norm/">slideflow.norm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../simclr/">slideflow.simclr</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../slide/">slideflow.slide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../slide_qc/">slideflow.slide.qc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../stats/">slideflow.stats</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../util/">slideflow.util</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../studio_module/">slideflow.studio</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial1/">Tutorial 1: Model training (simple)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial2/">Tutorial 2: Model training (advanced)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial3/">Tutorial 3: Using a custom architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial4/">Tutorial 4: Model evaluation &amp; heatmaps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial5/">Tutorial 5: Creating a mosaic map</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial6/">Tutorial 6: Custom slide filtering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial7/">Tutorial 7: Training with custom augmentations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial8/">Tutorial 8: Multiple-Instance Learning</a></li>
</ul>



        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">

      <li>
        <a href="../../../">

            Docs

        </a> &gt;
      </li>


          <li><a href="../../">Module code</a> &gt;</li>

      <li>slideflow.norm</li>


      <li class="pytorch-breadcrumbs-aside">

      </li>

  </ul>


</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">



          <div class="rst-content">

            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">

  <h1>Source code for slideflow.norm</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;H&amp;E stain normalization and augmentation tools.&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">multiprocessing</span> <span class="k">as</span> <span class="nn">mp</span>
<span class="kn">from</span> <span class="nn">io</span> <span class="kn">import</span> <span class="n">BytesIO</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">TYPE_CHECKING</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">slideflow</span> <span class="k">as</span> <span class="nn">sf</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">contextlib</span> <span class="kn">import</span> <span class="n">contextmanager</span>
<span class="kn">from</span> <span class="nn">rich.progress</span> <span class="kn">import</span> <span class="n">Progress</span>
<span class="kn">from</span> <span class="nn">slideflow</span> <span class="kn">import</span> <span class="n">errors</span>
<span class="kn">from</span> <span class="nn">slideflow.dataset</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">slideflow.util</span> <span class="kn">import</span> <span class="n">detuple</span><span class="p">,</span> <span class="n">log</span><span class="p">,</span> <span class="n">cleanup_progress</span><span class="p">,</span> <span class="n">_as_list</span>
<span class="kn">from</span> <span class="nn">slideflow.norm</span> <span class="kn">import</span> <span class="p">(</span><span class="n">augment</span><span class="p">,</span> <span class="n">macenko</span><span class="p">,</span> <span class="n">reinhard</span><span class="p">,</span> <span class="n">vahadane</span><span class="p">)</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
    <span class="kn">import</span> <span class="nn">torch</span>


<div class="viewcode-block" id="StainNormalizer"><a class="viewcode-back" href="../../../norm/#slideflow.norm.StainNormalizer">[docs]</a><span class="k">class</span> <span class="nc">StainNormalizer</span><span class="p">:</span>

    <span class="n">vectorized</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">normalizers</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;macenko&#39;</span><span class="p">:</span>  <span class="n">macenko</span><span class="o">.</span><span class="n">MacenkoNormalizer</span><span class="p">,</span>
        <span class="s1">&#39;macenko_fast&#39;</span><span class="p">:</span>  <span class="n">macenko</span><span class="o">.</span><span class="n">MacenkoFastNormalizer</span><span class="p">,</span>
        <span class="s1">&#39;reinhard&#39;</span><span class="p">:</span> <span class="n">reinhard</span><span class="o">.</span><span class="n">ReinhardNormalizer</span><span class="p">,</span>
        <span class="s1">&#39;reinhard_fast&#39;</span><span class="p">:</span> <span class="n">reinhard</span><span class="o">.</span><span class="n">ReinhardFastNormalizer</span><span class="p">,</span>
        <span class="s1">&#39;reinhard_mask&#39;</span><span class="p">:</span> <span class="n">reinhard</span><span class="o">.</span><span class="n">ReinhardMaskNormalizer</span><span class="p">,</span>
        <span class="s1">&#39;reinhard_fast_mask&#39;</span><span class="p">:</span> <span class="n">reinhard</span><span class="o">.</span><span class="n">ReinhardFastMaskNormalizer</span><span class="p">,</span>
        <span class="s1">&#39;vahadane&#39;</span><span class="p">:</span> <span class="n">vahadane</span><span class="o">.</span><span class="n">VahadaneSpamsNormalizer</span><span class="p">,</span>
        <span class="s1">&#39;vahadane_sklearn&#39;</span><span class="p">:</span> <span class="n">vahadane</span><span class="o">.</span><span class="n">VahadaneSklearnNormalizer</span><span class="p">,</span>
        <span class="s1">&#39;vahadane_spams&#39;</span><span class="p">:</span> <span class="n">vahadane</span><span class="o">.</span><span class="n">VahadaneSpamsNormalizer</span><span class="p">,</span>
        <span class="s1">&#39;augment&#39;</span><span class="p">:</span> <span class="n">augment</span><span class="o">.</span><span class="n">AugmentNormalizer</span>
    <span class="p">}</span>  <span class="c1"># type: Dict[str, Any]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;H&amp;E Stain normalizer supporting various normalization methods.</span>

<span class="sd">        The stain normalizer supports numpy images, PNG or JPG strings,</span>
<span class="sd">        Tensorflow tensors, and PyTorch tensors. The default ``.transform()``</span>
<span class="sd">        method will attempt to preserve the original image type while</span>
<span class="sd">        minimizing conversions to and from Tensors.</span>

<span class="sd">        Alternatively, you can manually specify the image conversion type</span>
<span class="sd">        by using the appropriate function. For example, to convert a Tensor</span>
<span class="sd">        to a normalized numpy RGB image, use ``.tf_to_rgb()``.</span>

<span class="sd">        Args:</span>
<span class="sd">            method (str): Normalization method. Options include &#39;macenko&#39;,</span>
<span class="sd">                &#39;reinhard&#39;, &#39;reinhard_fast&#39;, &#39;reinhard_mask&#39;,</span>
<span class="sd">                &#39;reinhard_fast_mask&#39;, &#39;vahadane&#39;, &#39;vahadane_spams&#39;,</span>
<span class="sd">                &#39;vahadane_sklearn&#39;, and &#39;augment&#39;.</span>

<span class="sd">        Keyword args:</span>
<span class="sd">            stain_matrix_target (np.ndarray, optional): Set the stain matrix</span>
<span class="sd">                target for the normalizer. May raise an error if the normalizer</span>
<span class="sd">                does not have a stain_matrix_target fit attribute.</span>
<span class="sd">            target_concentrations (np.ndarray, optional): Set the target</span>
<span class="sd">                concentrations for the normalizer. May raise an error if the</span>
<span class="sd">                normalizer does not have a target_concentrations fit attribute.</span>
<span class="sd">            target_means (np.ndarray, optional): Set the target means for the</span>
<span class="sd">                normalizer. May raise an error if the normalizer does not have</span>
<span class="sd">                a target_means fit attribute.</span>
<span class="sd">            target_stds (np.ndarray, optional): Set the target standard</span>
<span class="sd">                deviations for the normalizer. May raise an error if the</span>
<span class="sd">                normalizer does not have a target_stds fit attribute.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the specified normalizer method is not available.</span>

<span class="sd">        Examples</span>
<span class="sd">            Normalize a numpy image using the default fit.</span>

<span class="sd">                &gt;&gt;&gt; import slideflow as sf</span>
<span class="sd">                &gt;&gt;&gt; macenko = sf.norm.StainNormalizer(&#39;macenko&#39;)</span>
<span class="sd">                &gt;&gt;&gt; macenko.transform(image)</span>

<span class="sd">            Fit the normalizer to a target image (numpy or path).</span>

<span class="sd">                &gt;&gt;&gt; macenko.fit(target_image)</span>

<span class="sd">            Fit the normalizer using a preset configuration.</span>

<span class="sd">                &gt;&gt;&gt; macenko.fit(&#39;v2&#39;)</span>

<span class="sd">            Fit the normalizer to all images in a Dataset.</span>

<span class="sd">                &gt;&gt;&gt; dataset = sf.Dataset(...)</span>
<span class="sd">                &gt;&gt;&gt; macenko.fit(dataset)</span>

<span class="sd">            Normalize an image and convert from Tensor to numpy array (RGB).</span>

<span class="sd">                &gt;&gt;&gt; macenko.tf_to_rgb(image)</span>

<span class="sd">            Normalize images during DataLoader pre-processing.</span>

<span class="sd">                &gt;&gt;&gt; dataset = sf.Dataset(...)</span>
<span class="sd">                &gt;&gt;&gt; dataloader = dataset.torch(..., normalizer=macenko)</span>
<span class="sd">                &gt;&gt;&gt; dts = dataset.tensorflow(..., normalizer=macenko)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalizers</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unrecognized normalizer method </span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalizers</span><span class="p">[</span><span class="n">method</span><span class="p">]()</span>

        <span class="k">if</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">base</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">(</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
        <span class="n">base</span> <span class="o">+=</span> <span class="s2">&quot;  method = </span><span class="si">{!r}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">fit_param</span><span class="p">,</span> <span class="n">fit_val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_fit</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">base</span> <span class="o">+=</span> <span class="s2">&quot;  </span><span class="si">{}</span><span class="s2"> = </span><span class="si">{!r}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fit_param</span><span class="p">,</span> <span class="n">fit_val</span><span class="p">)</span>
        <span class="n">base</span> <span class="o">+=</span> <span class="s2">&quot;)&quot;</span>
        <span class="k">return</span> <span class="n">base</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">&#39;cpu&#39;</span>

    <span class="k">def</span> <span class="nf">_torch_transform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inp</span><span class="p">:</span> <span class="s2">&quot;torch.Tensor&quot;</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">augment</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;torch.Tensor&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Normalize a torch uint8 image (CWH).</span>

<span class="sd">        Normalization ocurs via intermediate conversion to WHC.</span>

<span class="sd">        Args:</span>
<span class="sd">            inp (torch.Tensor): Image, uint8. Images are normalized in</span>
<span class="sd">                W x H x C space. Images provided as C x W x H will be</span>
<span class="sd">                auto-converted and permuted back after normalization.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor:   Image, uint8.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">torch</span>
        <span class="kn">from</span> <span class="nn">slideflow.io.torch</span> <span class="kn">import</span> <span class="n">cwh_to_whc</span><span class="p">,</span> <span class="n">whc_to_cwh</span><span class="p">,</span> <span class="n">is_cwh</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_torch_transform</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">inp</span><span class="p">])</span>
        <span class="k">elif</span> <span class="n">is_cwh</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span>
            <span class="c1"># Convert from CWH -&gt; WHC (normalize) -&gt; CWH</span>
            <span class="k">return</span> <span class="n">whc_to_cwh</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">rgb_to_rgb</span><span class="p">(</span>
                        <span class="n">cwh_to_whc</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
                        <span class="n">augment</span><span class="o">=</span><span class="n">augment</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">rgb_to_rgb</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">augment</span><span class="o">=</span><span class="n">augment</span><span class="p">)</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_torch_augment</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">:</span> <span class="s2">&quot;torch.Tensor&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;torch.Tensor&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Augment a torch uint8 image (CWH).</span>

<span class="sd">        Augmentation ocurs via intermediate conversion to WHC.</span>

<span class="sd">        Args:</span>
<span class="sd">            inp (torch.Tensor): Image, uint8. Images are normalized in</span>
<span class="sd">                W x H x C space. Images provided as C x W x H will be</span>
<span class="sd">                auto-converted and permuted back after normalization.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor:   Image, uint8.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">torch</span>
        <span class="kn">from</span> <span class="nn">slideflow.io.torch</span> <span class="kn">import</span> <span class="n">cwh_to_whc</span><span class="p">,</span> <span class="n">whc_to_cwh</span><span class="p">,</span> <span class="n">is_cwh</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_torch_augment</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">inp</span><span class="p">])</span>
        <span class="k">elif</span> <span class="n">is_cwh</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span>
            <span class="c1"># Convert from CWH -&gt; WHC (normalize) -&gt; CWH</span>
            <span class="k">return</span> <span class="n">whc_to_cwh</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">augment_rgb</span><span class="p">(</span><span class="n">cwh_to_whc</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">augment_rgb</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">arg1</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">str</span><span class="p">]],</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
        <span class="n">num_threads</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;StainNormalizer&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit the normalizer to a target image or dataset of images.</span>

<span class="sd">        Args:</span>
<span class="sd">            arg1: (Dataset, np.ndarray, str): Target to fit. May be a str,</span>
<span class="sd">                numpy image array (uint8), path to an image, or a Slideflow</span>
<span class="sd">                Dataset. If this is a string, will fit to the corresponding</span>
<span class="sd">                preset fit (either &#39;v1&#39;, &#39;v2&#39;, or &#39;v3&#39;).</span>
<span class="sd">                If a Dataset is provided, will average fit values across</span>
<span class="sd">                all images in the dataset.</span>
<span class="sd">            batch_size (int, optional): Batch size during fitting, if fitting</span>
<span class="sd">                to dataset. Defaults to 64.</span>
<span class="sd">            num_threads (Union[str, int], optional): Number of threads to use</span>
<span class="sd">                during fitting, if fitting to a dataset. Defaults to &#39;auto&#39;.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Fit to a dataset</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">):</span>
            <span class="c1"># Set up thread pool</span>
            <span class="k">if</span> <span class="n">num_threads</span> <span class="o">==</span> <span class="s1">&#39;auto&#39;</span><span class="p">:</span>
                <span class="n">num_threads</span> <span class="o">=</span> <span class="n">sf</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">num_cpu</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting up pool (size=</span><span class="si">{</span><span class="n">num_threads</span><span class="si">}</span><span class="s2">) for norm fitting&quot;</span><span class="p">)</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using normalizer batch size of </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">pool</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">dummy</span><span class="o">.</span><span class="n">Pool</span><span class="p">(</span><span class="n">num_threads</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

            <span class="n">dataset</span> <span class="o">=</span> <span class="n">arg1</span>
            <span class="k">if</span> <span class="n">sf</span><span class="o">.</span><span class="n">backend</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;tensorflow&#39;</span><span class="p">:</span>
                <span class="n">dts</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">tensorflow</span><span class="p">(</span>
                    <span class="kc">None</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">standardize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">infinite</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">sf</span><span class="o">.</span><span class="n">backend</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;torch&#39;</span><span class="p">:</span>
                <span class="n">dts</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">torch</span><span class="p">(</span>
                    <span class="kc">None</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">standardize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">infinite</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span>
                <span class="p">)</span>
            <span class="n">all_fit_vals</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># type: ignore</span>
            <span class="n">pb</span> <span class="o">=</span> <span class="n">Progress</span><span class="p">(</span><span class="n">transient</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">task</span> <span class="o">=</span> <span class="n">pb</span><span class="o">.</span><span class="n">add_task</span><span class="p">(</span><span class="s1">&#39;Fitting normalizer...&#39;</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">num_tiles</span><span class="p">)</span>
            <span class="n">pb</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
            <span class="k">with</span> <span class="n">cleanup_progress</span><span class="p">(</span><span class="n">pb</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">img_batch</span><span class="p">,</span> <span class="n">slide</span> <span class="ow">in</span> <span class="n">dts</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">sf</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">is_torch_tensor</span><span class="p">(</span><span class="n">img_batch</span><span class="p">):</span>
                        <span class="n">img_batch</span> <span class="o">=</span> <span class="n">img_batch</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># BCWH -&gt; BWHC</span>

                    <span class="n">mapped</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">imap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">()),</span> <span class="n">img_batch</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">fit_vals</span> <span class="ow">in</span> <span class="n">mapped</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">all_fit_vals</span> <span class="o">==</span> <span class="p">[]:</span>
                            <span class="n">all_fit_vals</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">fit_vals</span><span class="p">))]</span>
                        <span class="k">for</span> <span class="n">v</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">fit_vals</span><span class="p">):</span>
                            <span class="n">all_fit_vals</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">+=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">val</span><span class="p">)]</span>
                    <span class="n">pb</span><span class="o">.</span><span class="n">advance</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">.</span><span class="n">set_fit</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">all_fit_vals</span><span class="p">])</span>
            <span class="n">pool</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="c1"># Fit to numpy image</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Fit to a preset</span>
        <span class="k">elif</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
              <span class="ow">and</span> <span class="n">arg1</span> <span class="ow">in</span> <span class="n">sf</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">fit_presets</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">.</span><span class="n">preset_tag</span><span class="p">]):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">.</span><span class="n">fit_preset</span><span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Fit to a path to an image</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">src_img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">arg1</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">src_img</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">arg1</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_fit</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Unrecognized args for fit: </span><span class="si">{</span><span class="n">arg1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">&#39;Fit normalizer: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">fit_key</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">fit_val</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">for</span> <span class="n">fit_key</span><span class="p">,</span> <span class="n">fit_val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_fit</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span>
        <span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">get_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">as_list</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the current normalizer fit.</span>

<span class="sd">        Args:</span>
<span class="sd">            as_list (bool). Convert the fit values (numpy arrays) to list</span>
<span class="sd">                format. Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dict[str, np.ndarray]: Dictionary mapping fit parameters (e.g.</span>
<span class="sd">            &#39;target_concentrations&#39;) to their respective fit values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_fit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">.</span><span class="n">get_fit</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">as_list</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">_as_list</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">_fit</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_fit</span>

    <span class="k">def</span> <span class="nf">set_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the normalizer fit to the given values.</span>

<span class="sd">        Keyword args:</span>
<span class="sd">            stain_matrix_target (np.ndarray, optional): Set the stain matrix</span>
<span class="sd">                target for the normalizer. May raise an error if the normalizer</span>
<span class="sd">                does not have a stain_matrix_target fit attribute.</span>
<span class="sd">            target_concentrations (np.ndarray, optional): Set the target</span>
<span class="sd">                concentrations for the normalizer. May raise an error if the</span>
<span class="sd">                normalizer does not have a target_concentrations fit attribute.</span>
<span class="sd">            target_means (np.ndarray, optional): Set the target means for the</span>
<span class="sd">                normalizer. May raise an error if the normalizer does not have</span>
<span class="sd">                a target_means fit attribute.</span>
<span class="sd">            target_stds (np.ndarray, optional): Set the target standard</span>
<span class="sd">                deviations for the normalizer. May raise an error if the</span>
<span class="sd">                normalizer does not have a target_stds fit attribute.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">.</span><span class="n">set_fit</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="n">k</span><span class="p">:</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">})</span>

    <span class="k">def</span> <span class="nf">set_augment</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">preset</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the normalizer augmentation space.</span>

<span class="sd">        Args:</span>
<span class="sd">            preset (str, optional): Augmentation preset. Defaults to None.</span>

<span class="sd">        Keyword args:</span>
<span class="sd">            matrix_stdev (np.ndarray): Standard deviation</span>
<span class="sd">                of the stain matrix target. Must have the shape (3, 2).</span>
<span class="sd">                Used for Macenko normalizers.</span>
<span class="sd">                Defaults to None (will not augment stain matrix).</span>
<span class="sd">            concentrations_stdev (np.ndarray): Standard deviation</span>
<span class="sd">                of the target concentrations. Must have the shape (2,).</span>
<span class="sd">                Used for Macenko normalizers.</span>
<span class="sd">                Defaults to None (will not augment target concentrations).</span>
<span class="sd">            means_stdev (np.ndarray): Standard deviation</span>
<span class="sd">                of the target means. Must have the shape (3,).</span>
<span class="sd">                Used for Reinhard normalizers.</span>
<span class="sd">                Defaults to None (will not augment target means).</span>
<span class="sd">            stds_stdev (np.ndarray): Standard deviation</span>
<span class="sd">                of the target stds. Must have the shape (3,).</span>
<span class="sd">                Used for Reinhard normalizers.</span>
<span class="sd">                Defaults to None (will not augment target stds).</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">preset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">.</span><span class="n">augment_preset</span><span class="p">(</span><span class="n">preset</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">.</span><span class="n">set_augment</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="n">k</span><span class="p">:</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">})</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="s2">&quot;tf.Tensor&quot;</span><span class="p">,</span> <span class="s2">&quot;torch.Tensor&quot;</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">augment</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="s2">&quot;tf.Tensor&quot;</span><span class="p">,</span> <span class="s2">&quot;torch.Tensor&quot;</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Normalize a target image, attempting to preserve the original type.</span>

<span class="sd">        Args:</span>
<span class="sd">            image (np.ndarray, tf.Tensor, or torch.Tensor): Image as a uint8</span>
<span class="sd">                array. Numpy and Tensorflow images are normalized in W x H x C</span>
<span class="sd">                space. PyTorch images provided as C x W x H will be</span>
<span class="sd">                auto-converted and permuted back after normalization.</span>

<span class="sd">        Keyword args:</span>
<span class="sd">            augment (bool): Transform using stain aumentation.</span>
<span class="sd">                Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Normalized image of the original type (uint8).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unable to auto-transform bytes or str; please &quot;</span>
                             <span class="s2">&quot;use .png_to_png() or .jpeg_to_jpeg().&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="s1">&#39;tensorflow&#39;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_to_tf</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">augment</span><span class="o">=</span><span class="n">augment</span><span class="p">)</span>
        <span class="k">if</span> <span class="s1">&#39;torch&#39;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">torch</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">torch_to_torch</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">augment</span><span class="o">=</span><span class="n">augment</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rgb_to_rgb</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">augment</span><span class="o">=</span><span class="n">augment</span><span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unrecognized image type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">image</span><span class="p">)</span><span class="si">}</span><span class="s2">; expected &quot;</span>
                         <span class="s2">&quot;np.ndarray, tf.Tensor, or torch.Tensor&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">augment</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="s2">&quot;tf.Tensor&quot;</span><span class="p">,</span> <span class="s2">&quot;torch.Tensor&quot;</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="s2">&quot;tf.Tensor&quot;</span><span class="p">,</span> <span class="s2">&quot;torch.Tensor&quot;</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Augment a target image, attempting to preserve the original type.</span>

<span class="sd">        Args:</span>
<span class="sd">            image (np.ndarray, tf.Tensor, or torch.Tensor): Image as a uint8</span>
<span class="sd">                array. Numpy and Tensorflow images are normalized in W x H x C</span>
<span class="sd">                space. PyTorch images provided as C x W x H will be</span>
<span class="sd">                auto-converted and permuted back after normalization.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Augmented image of the original type (uint8).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="s1">&#39;augment&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">errors</span><span class="o">.</span><span class="n">AugmentationNotSupportedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Normalizer </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="si">}</span><span class="s2"> does not support augmentation.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unable to augment bytes or str; image &quot;</span>
                             <span class="s2">&quot;must first be converted to an array or Tensor.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="s1">&#39;tensorflow&#39;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                    <span class="n">image</span><span class="p">[</span><span class="s1">&#39;tile_image&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">py_function</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">augment_rgb</span><span class="p">,</span>
                        <span class="p">[</span><span class="n">image</span><span class="p">[</span><span class="s1">&#39;tile_image&#39;</span><span class="p">]],</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">uint8</span>
                    <span class="p">)</span>
                <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
                    <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">augment_rgb</span><span class="p">(</span><span class="n">_i</span><span class="p">)</span> <span class="k">for</span> <span class="n">_i</span> <span class="ow">in</span> <span class="n">image</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">py_function</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">augment_rgb</span><span class="p">,</span>
                        <span class="p">[</span><span class="n">image</span><span class="p">],</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">uint8</span>
                    <span class="p">)</span>
                <span class="k">return</span> <span class="n">image</span>

        <span class="k">if</span> <span class="s1">&#39;torch&#39;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">torch</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                    <span class="n">to_return</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">image</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                        <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="s1">&#39;tile_image&#39;</span>
                    <span class="p">}</span>
                    <span class="n">to_return</span><span class="p">[</span><span class="s1">&#39;tile_image&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_torch_augment</span><span class="p">(</span>
                        <span class="n">image</span><span class="p">[</span><span class="s1">&#39;tile_image&#39;</span><span class="p">]</span>
                    <span class="p">)</span>
                    <span class="k">return</span> <span class="n">to_return</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_torch_augment</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">augment_rgb</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unrecognized image type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">image</span><span class="p">)</span><span class="si">}</span><span class="s2">; expected &quot;</span>
                            <span class="s2">&quot;np.ndarray, tf.Tensor, or torch.Tensor&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">augment_rgb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Augment a numpy array (uint8), returning a numpy array (uint8).</span>

<span class="sd">        Args:</span>
<span class="sd">            image (np.ndarray): Image (uint8).</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray: Augmented image, uint8, W x H x C.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">.</span><span class="n">augment</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">jpeg_to_jpeg</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">jpeg_string</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">quality</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">augment</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bytes</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Normalize a JPEG image, returning a JPEG image.</span>

<span class="sd">        Args:</span>
<span class="sd">            jpeg_string (str, bytes): JPEG image data.</span>

<span class="sd">        Keyword args:</span>
<span class="sd">            augment (bool): Transform using stain aumentation.</span>
<span class="sd">                Defaults to False.</span>
<span class="sd">            quality (int, optional): Quality level for creating the resulting</span>
<span class="sd">                normalized JPEG image. Defaults to 100.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bytes:  Normalized JPEG image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cv_image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">jpeg_to_rgb</span><span class="p">(</span><span class="n">jpeg_string</span><span class="p">,</span> <span class="n">augment</span><span class="o">=</span><span class="n">augment</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">BytesIO</span><span class="p">()</span> <span class="k">as</span> <span class="n">output</span><span class="p">:</span>
            <span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">cv_image</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
                <span class="n">output</span><span class="p">,</span>
                <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;JPEG&quot;</span><span class="p">,</span>
                <span class="n">quality</span><span class="o">=</span><span class="n">quality</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">output</span><span class="o">.</span><span class="n">getvalue</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">jpeg_to_rgb</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">jpeg_string</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">augment</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Normalize a JPEG image, returning a numpy uint8 array.</span>

<span class="sd">        Args:</span>
<span class="sd">            jpeg_string (str, bytes): JPEG image data.</span>

<span class="sd">        Keyword args:</span>
<span class="sd">            augment (bool): Transform using stain aumentation.</span>
<span class="sd">                Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray: Normalized image, uint8, W x H x C.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cv_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imdecode</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">fromstring</span><span class="p">(</span><span class="n">jpeg_string</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">),</span>
            <span class="n">cv2</span><span class="o">.</span><span class="n">IMREAD_COLOR</span>
        <span class="p">)</span>
        <span class="n">cv_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">cv_image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rgb_to_rgb</span><span class="p">(</span><span class="n">cv_image</span><span class="p">,</span> <span class="n">augment</span><span class="o">=</span><span class="n">augment</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">png_to_png</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">png_string</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">augment</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bytes</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Normalize a PNG image, returning a PNG image.</span>

<span class="sd">        Args:</span>
<span class="sd">            png_string (str, bytes): PNG image data.</span>

<span class="sd">        Keyword args:</span>
<span class="sd">            augment (bool): Transform using stain aumentation.</span>
<span class="sd">                Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bytes: Normalized PNG image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cv_image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">png_to_rgb</span><span class="p">(</span><span class="n">png_string</span><span class="p">,</span> <span class="n">augment</span><span class="o">=</span><span class="n">augment</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">BytesIO</span><span class="p">()</span> <span class="k">as</span> <span class="n">output</span><span class="p">:</span>
            <span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">cv_image</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;PNG&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">output</span><span class="o">.</span><span class="n">getvalue</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">png_to_rgb</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">png_string</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">augment</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Normalize a PNG image, returning a numpy uint8 array.</span>

<span class="sd">        Args:</span>
<span class="sd">            png_string (str, bytes): PNG image data.</span>

<span class="sd">        Keyword args:</span>
<span class="sd">            augment (bool): Transform using stain aumentation.</span>
<span class="sd">                Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray: Normalized image, uint8, W x H x C.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">jpeg_to_rgb</span><span class="p">(</span><span class="n">png_string</span><span class="p">,</span> <span class="n">augment</span><span class="o">=</span><span class="n">augment</span><span class="p">)</span>  <span class="c1"># It should auto-detect format</span>

    <span class="k">def</span> <span class="nf">rgb_to_rgb</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">augment</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Normalize a numpy array (uint8), returning a numpy array (uint8).</span>

<span class="sd">        Args:</span>
<span class="sd">            image (np.ndarray): Image (uint8).</span>

<span class="sd">        Keyword args:</span>
<span class="sd">            augment (bool): Transform using stain aumentation.</span>
<span class="sd">                Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray: Normalized image, uint8, W x H x C.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">augment</span><span class="o">=</span><span class="n">augment</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">tf_to_rgb</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image</span><span class="p">:</span> <span class="s2">&quot;tf.Tensor&quot;</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">augment</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Normalize a tf.Tensor (uint8), returning a numpy array (uint8).</span>

<span class="sd">        Args:</span>
<span class="sd">            image (tf.Tensor): Image (uint8).</span>

<span class="sd">        Keyword args:</span>
<span class="sd">            augment (bool): Transform using stain aumentation.</span>
<span class="sd">                Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray: Normalized image, uint8, W x H x C.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rgb_to_rgb</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">image</span><span class="p">),</span> <span class="n">augment</span><span class="o">=</span><span class="n">augment</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">tf_to_tf</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="s2">&quot;tf.Tensor&quot;</span><span class="p">],</span>
        <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">augment</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="s2">&quot;tf.Tensor&quot;</span><span class="p">],</span> <span class="o">...</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Normalize a tf.Tensor (uint8), returning a numpy array (uint8).</span>

<span class="sd">        Args:</span>
<span class="sd">            image (tf.Tensor, Dict): Image (uint8) either as a raw Tensor,</span>
<span class="sd">                or a Dictionary with the image under the key &#39;tile_image&#39;.</span>
<span class="sd">            args (Any, optional): Any additional arguments, which will be passed</span>
<span class="sd">                and returned unmodified.</span>

<span class="sd">        Keyword args:</span>
<span class="sd">            augment (bool): Transform using stain aumentation.</span>
<span class="sd">                Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A tuple containing the normalized tf.Tensor image (uint8,</span>
<span class="sd">            W x H x C) and any additional arguments provided.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">image</span><span class="p">[</span><span class="s1">&#39;tile_image&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">py_function</span><span class="p">(</span>
                <span class="n">partial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tf_to_rgb</span><span class="p">,</span> <span class="n">augment</span><span class="o">=</span><span class="n">augment</span><span class="p">),</span>
                <span class="p">[</span><span class="n">image</span><span class="p">[</span><span class="s1">&#39;tile_image&#39;</span><span class="p">]],</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">uint8</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">tf_to_tf</span><span class="p">(</span><span class="n">_i</span><span class="p">,</span> <span class="n">augment</span><span class="o">=</span><span class="n">augment</span><span class="p">)</span> <span class="k">for</span> <span class="n">_i</span> <span class="ow">in</span> <span class="n">image</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">py_function</span><span class="p">(</span>
                <span class="n">partial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tf_to_rgb</span><span class="p">,</span> <span class="n">augment</span><span class="o">=</span><span class="n">augment</span><span class="p">),</span>
                <span class="p">[</span><span class="n">image</span><span class="p">],</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">uint8</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">detuple</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">torch_to_torch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="s2">&quot;torch.Tensor&quot;</span><span class="p">],</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="n">augment</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="s2">&quot;torch.Tensor&quot;</span><span class="p">],</span> <span class="o">...</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Normalize a torch.Tensor (uint8), returning a numpy array (uint8).</span>

<span class="sd">        Args:</span>
<span class="sd">            image (torch.Tensor, Dict): Image (uint8) either as a raw Tensor,</span>
<span class="sd">                or a Dictionary with the image under the key &#39;tile_image&#39;.</span>
<span class="sd">            args (Any, optional): Any additional arguments, which will be passed</span>
<span class="sd">                and returned unmodified.</span>

<span class="sd">        Keyword args:</span>
<span class="sd">            augment (bool): Transform using stain aumentation.</span>
<span class="sd">                Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A tuple containing</span>

<span class="sd">                np.ndarray: Normalized torch.Tensor image, uint8 (channel dimension matching the input image)</span>

<span class="sd">                args (Any, optional): Any additional arguments provided, unmodified.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">to_return</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">image</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="s1">&#39;tile_image&#39;</span>
            <span class="p">}</span>
            <span class="n">to_return</span><span class="p">[</span><span class="s1">&#39;tile_image&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_torch_transform</span><span class="p">(</span>
                <span class="n">image</span><span class="p">[</span><span class="s1">&#39;tile_image&#39;</span><span class="p">],</span>
                <span class="n">augment</span><span class="o">=</span><span class="n">augment</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">detuple</span><span class="p">(</span><span class="n">to_return</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">detuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_torch_transform</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">augment</span><span class="o">=</span><span class="n">augment</span><span class="p">),</span> <span class="n">args</span><span class="p">)</span>

    <span class="c1"># --- Context management --------------------------------------------------</span>

    <span class="nd">@contextmanager</span>
    <span class="k">def</span> <span class="nf">context</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">context</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;sf.WSI&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="s2">&quot;tf.Tensor&quot;</span><span class="p">,</span> <span class="s2">&quot;torch.Tensor&quot;</span><span class="p">]</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the whole-slide context for the stain normalizer.</span>

<span class="sd">        With contextual normalization, max concentrations are determined</span>
<span class="sd">        from the context (whole-slide image) rather than the image being</span>
<span class="sd">        normalized. This may improve stain normalization for sections of</span>
<span class="sd">        a slide that are predominantly eosin (e.g. necrosis or low cellularity).</span>

<span class="sd">        When calculating max concentrations from the image context,</span>
<span class="sd">        white pixels (255) will be masked.</span>

<span class="sd">        This function is a context manager used for temporarily setting the</span>
<span class="sd">        image context. For example:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            with normalizer.context(slide):</span>
<span class="sd">                normalizer.transform(target)</span>

<span class="sd">        If a slide (``sf.WSI``) is used for context, any existing QC filters</span>
<span class="sd">        and regions of interest will be used to mask out background as white</span>
<span class="sd">        pixels, and the masked thumbnail will be used for creating the</span>
<span class="sd">        normalizer context. If no QC has been applied to the slide and the</span>
<span class="sd">        slide does not have any Regions of Interest, then both otsu&#39;s</span>
<span class="sd">        thresholding and Gaussian blur filtering will be applied</span>
<span class="sd">        to the thumbnail for masking.</span>

<span class="sd">        Args:</span>
<span class="sd">            I (np.ndarray, sf.WSI): Context to use for normalization, e.g.</span>
<span class="sd">                a whole-slide image thumbnail, optionally masked with masked</span>
<span class="sd">                areas set to (255, 255, 255).</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
        <span class="k">yield</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clear_context</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">set_context</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">context</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;sf.WSI&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="s2">&quot;tf.Tensor&quot;</span><span class="p">,</span> <span class="s2">&quot;torch.Tensor&quot;</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the whole-slide context for the stain normalizer.</span>

<span class="sd">        With contextual normalization, max concentrations are determined</span>
<span class="sd">        from the context (whole-slide image) rather than the image being</span>
<span class="sd">        normalized. This may improve stain normalization for sections of</span>
<span class="sd">        a slide that are predominantly eosin (e.g. necrosis or low cellularity).</span>

<span class="sd">        When calculating max concentrations from the image context,</span>
<span class="sd">        white pixels (255) will be masked.</span>

<span class="sd">        If a slide (``sf.WSI``) is used for context, any existing QC filters</span>
<span class="sd">        and regions of interest will be used to mask out background as white</span>
<span class="sd">        pixels, and the masked thumbnail will be used for creating the</span>
<span class="sd">        normalizer context. If no QC has been applied to the slide and the</span>
<span class="sd">        slide does not have any Regions of Interest, then both otsu&#39;s</span>
<span class="sd">        thresholding and Gaussian blur filtering will be applied</span>
<span class="sd">        to the thumbnail for masking.</span>

<span class="sd">        Args:</span>
<span class="sd">            I (np.ndarray, sf.WSI): Context to use for normalization, e.g.</span>
<span class="sd">                a whole-slide image thumbnail, optionally masked with masked</span>
<span class="sd">                areas set to (255, 255, 255).</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="s1">&#39;set_context&#39;</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">sf</span><span class="o">.</span><span class="n">WSI</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span><span class="o">.</span><span class="n">thumb</span><span class="p">(</span><span class="n">mpp</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">sf</span><span class="o">.</span><span class="n">WSI</span><span class="p">):</span>
                <span class="n">image</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">masked_thumb</span><span class="p">(</span><span class="n">mpp</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">background</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">image</span> <span class="o">=</span> <span class="n">context</span>  <span class="c1"># type: ignore</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">clear_context</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Remove any previously set stain normalizer context.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="s1">&#39;clear_context&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">.</span><span class="n">clear_context</span><span class="p">()</span></div>


<span class="k">def</span> <span class="nf">autoselect</span><span class="p">(</span>
    <span class="n">method</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">source</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">backend</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">StainNormalizer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Select the best normalizer for a given method, and fit to a given source.</span>

<span class="sd">    If a normalizer method has a native implementation in the current backend</span>
<span class="sd">    (Tensorflow or PyTorch), the native normalizer will be used.</span>
<span class="sd">    If not, the default numpy implementation will be used.</span>

<span class="sd">    Currently, the PyTorch-native normalizers are NOT used by default, as they</span>
<span class="sd">    are slower than the numpy implementations. Thus, with the PyTorch backend,</span>
<span class="sd">    all normalizers will be the default numpy implementations.</span>

<span class="sd">    Args:</span>
<span class="sd">        method (str): Normalization method. Options include &#39;macenko&#39;,</span>
<span class="sd">            &#39;reinhard&#39;, &#39;reinhard_fast&#39;, &#39;reinhard_mask&#39;, &#39;reinhard_fast_mask&#39;,</span>
<span class="sd">            &#39;vahadane&#39;, &#39;vahadane_spams&#39;, &#39;vahadane_sklearn&#39;, and &#39;augment&#39;.</span>
<span class="sd">        source (str, optional): Stain normalization preset or path to a source</span>
<span class="sd">            image. Valid presets include &#39;v1&#39;, &#39;v2&#39;, and &#39;v3&#39;. If None, will</span>
<span class="sd">            use the default present (&#39;v3&#39;). Defaults to None.</span>
<span class="sd">        backend (str): Backend to use for native normalizers. Options include</span>
<span class="sd">            &#39;tensorflow&#39;, &#39;torch&#39;, and &#39;opencv&#39;. If None, will use the current</span>
<span class="sd">            backend, falling back to opencv/numpy if a native normalizer is</span>
<span class="sd">            not available. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        StainNormalizer:    Initialized StainNormalizer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">backend</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">backend</span> <span class="o">=</span> <span class="n">sf</span><span class="o">.</span><span class="n">backend</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">backend</span> <span class="o">==</span> <span class="s1">&#39;tensorflow&#39;</span><span class="p">:</span>
        <span class="kn">import</span> <span class="nn">slideflow.norm.tensorflow</span>
        <span class="n">BackendNormalizer</span> <span class="o">=</span> <span class="n">sf</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">TensorflowStainNormalizer</span>
    <span class="k">elif</span> <span class="n">backend</span> <span class="o">==</span> <span class="s1">&#39;torch&#39;</span><span class="p">:</span>
        <span class="kn">import</span> <span class="nn">slideflow.norm.torch</span>
        <span class="n">BackendNormalizer</span> <span class="o">=</span> <span class="n">sf</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">TorchStainNormalizer</span>  <span class="c1"># type: ignore</span>
    <span class="k">elif</span> <span class="n">backend</span> <span class="o">==</span> <span class="s1">&#39;opencv&#39;</span><span class="p">:</span>
        <span class="n">BackendNormalizer</span> <span class="o">=</span> <span class="n">StainNormalizer</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">errors</span><span class="o">.</span><span class="n">UnrecognizedBackendError</span>

    <span class="k">if</span> <span class="n">method</span> <span class="ow">in</span> <span class="n">BackendNormalizer</span><span class="o">.</span><span class="n">normalizers</span><span class="p">:</span>
        <span class="n">normalizer</span> <span class="o">=</span> <span class="n">BackendNormalizer</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">normalizer</span> <span class="o">=</span> <span class="n">StainNormalizer</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

    <span class="k">if</span> <span class="n">source</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">source</span> <span class="o">!=</span> <span class="s1">&#39;dataset&#39;</span><span class="p">:</span>
        <span class="n">normalizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">normalizer</span>
</pre></div>

             </article>

            </div>
            <footer>




    <hr>



  <div role="contentinfo">
    <p>
        &copy; Copyright 2023, James M Dolezal.

    </p>
  </div>

      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>


</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">

            </div>
          </div>
        </div>
      </section>
    </div>







       <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
         <script src="../../../_static/doctools.js"></script>
         <script src="../../../_static/sphinx_highlight.js"></script>



  <script type="text/javascript" src="../../../_static/js/vendor/jquery-3.6.3.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  <!-- Begin Footer -->

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://slideflow.dev">Docs</a>
          </li>

          <li>
            <a href="https://slideflow.dev/tutorial1/">Tutorials</a>
          </li>

          <li>
            <a href="https://github.com/slideflow/slideflow">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script script type="text/javascript">
    var collapsedSections = [];
  </script>

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>